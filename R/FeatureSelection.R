#############################################################################
#
#  This file is a part of the R package "RoughSets".
#
#  Author: Lala Septem Riza and Andrzej Janusz
#  Supervisors: Chris Cornelis, Francisco Herrera, Dominik Slezak and Jose Manuel Benitez
#  Copyright (c):
#       DiCITS Lab, Sci2s group, DECSAI, University of Granada and
#       Institute of Mathematics, University of Warsaw
#
#  This package is free software: you can redistribute it and/or modify it under
#  the terms of the GNU General Public License as published by the Free Software
#  Foundation, either version 2 of the License, or (at your option) any later version.
#
#  This package is distributed in the hope that it will be useful, but WITHOUT
#  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
#  A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
#############################################################################
#' It is an additional function aimed as wrapper of approaches calculating a reduct. 
#' 
#' There exist three methods considered in this function based on RST and FRST as follows: 
#' \itemize{
#' \item \code{"greedy.heuristic"}: it is the greedy heuristic method based on RST. 
#'
#'                                  See \code{\link{FS.greedy.heuristic.reduct.RST}}.
#' \item \code{"nearOpt.fvprs"}: it is the near-optimal reduction algorithm based on FRST. 
#'
#'                               See \code{\link{FS.nearOpt.fvprs.FRST}}.
#' \item \code{"permutation.heuristic"}: it is the permutation heuristic approach based on RST. 
#'
#'                                       See \code{\link{FS.permutation.heuristic.reduct.RST}}.
#' }
#' Those methods can be selected by assigning the parameter \code{method}. 
#' Additionally, \code{\link{SF.applyDecTable}} has been provided to generate the new decision table. 
#' 
#' @title The reduct computation methods based on RST and FRST
#'
#' @param decision.table a \code{"DecisionTable"} class representing the decision table. See \code{\link{SF.asDecisionTable}}. 
#' @param method a character representing the type of methods. See in Section \code{Details}.
#' @param ... other parameters. See the parameters on \code{\link{FS.greedy.heuristic.reduct.RST}},
#' 
#'        \code{\link{FS.nearOpt.fvprs.FRST}} and \code{\link{FS.permutation.heuristic.reduct.RST}}.
#' @seealso \code{\link{D.discretization.RST}}, \code{\link{BC.LU.approximation.RST}}
#' @return A class \code{"FeatureSubset"}. See \code{\link{FS.greedy.heuristic.reduct.RST}} 
#'
#' or \code{\link{FS.nearOpt.fvprs.FRST}}.
#'
#' @examples
#' ##############################################################
#' ## Example 1: generate reduct and new decision table 
#' ## using RST and FRST
#' ##############################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$hiring.dt 
#'
#' ## generate single reduct using RST
#' reduct.1 <- FS.reduct.computation(decision.table, method = "permutation.heuristic")
#' 
#' ## generate single reduct using FRST
#' reduct.2 <- FS.reduct.computation(decision.table, method = "nearOpt.fvprs")
#' 
#' ## generate new decision table according to the reduct.1
#' new.decTable.1 <- SF.applyDecTable(decision.table, reduct.1) 
#'
#' ## generate new decision table according to the reduct.2
#' new.decTable.2 <- SF.applyDecTable(decision.table, reduct.2)
#'
#' @export
FS.reduct.computation <- function(decision.table, method = "greedy.heuristic", ...){
  
  if (!(method %in% c("greedy.heuristic", "permutation.heuristic", "nearOpt.fvprs"))) {
    stop("Unrecognized attribute reduction method.")
  }
  
  if(!inherits(decision.table, "DecisionTable")) {
    stop("Provided data should inherit from the \'DecisionTable\' class.")
  }
  
  nominal.att <- attr(decision.table, "nominal.attrs")
  if(!all(nominal.att) && !(method %in% "nearOpt.fvprs")) stop("Discretize attribures before computing RST reducts.")
  
  if(is.null(attr(decision.table, "decision.attr"))) stop("A decision attribute is not indicated.")
  else decIdx = attr(decision.table, "decision.attr")

  ## call the chosen method
  reduct = switch(method,  
                  greedy.heuristic = FS.greedy.heuristic.reduct.RST(decision.table, decisionIdx = decIdx, ...),
                  permutation.heuristic = FS.permutation.heuristic.reduct.RST(decision.table, decisionIdx = decIdx, ...),
                  nearOpt.fvprs = FS.nearOpt.fvprs.FRST(decision.table, ...) )
  
	return(reduct)  		
}


#' It is a function implementing the permutation heuristic approach based on RST.
#'
#' Basically there are two processes in this algorithm which are 
#' \itemize{
#' \item generating feature subset as superreduct: In this step, we choose a subset of attributes by 
#'       evaluating the discernibility relation of pairs of objects. 
#' \item eliminating feature subset to obtain a reduct: we iterate over the superreduct resulting from the previous process.
#'       Then, an attribute that is \emph{dispensable} in the subset is eliminated along iteration.
#' }
#' The detail of the algorithm can be seen in (Janusz and Slezak, 2012).
#' 
#' Additionally, \code{\link{SF.applyDecTable}} has been provided to generate new decision table. 
#' 
#' @title The permutation heuristic algorithm for determining a reduct
#'
#' @param decision.table a \code{"DecisionTable"} class representing the decision table. See \code{\link{SF.asDecisionTable}}. 
#' @param permutation a value representing whether we will randomize the conditional attributes or not. 
#'        The values of this parameter are \code{NULL} as default one and \code{FALSE}. 
#' @param decisionIdx an index of decision attribute. The default value is the last column of decision table.
#' @param ... other parameters.
#' @seealso \code{\link{FS.quickreduct.RST}} and \code{\link{FS.reduct.computation}}.
#' @return A class \code{"FeatureSubset"} that contains the following components:
#' \itemize{
#' \item \code{reduct}: a list representing a single reduct. In this case, it could be a superreduct or just a subset of features.
#' \item \code{type.method}: a string representing the type of method which is \code{"permutation.heuristic"}.
#' \item \code{type.task}: a string showing the type of task which is \code{"feature selection"}.
#' \item \code{model}: a string representing the type of model. In this case, it is \code{"RST"} which means rough set theory.
#' }  
#' @references
#' A. Janusz and D. Slezak, "Utilization of Attribute Clustering Methods for Scalable Computation of Reducts from High-Dimensional Data"
#'										Proceedings of Federated Conference on Computer Science and Information Systems - FedCSIS, p. 295 - 302 (2012).
#' @examples
#' ###################################################
#' ## Example 1: Generate reduct and new decision table
#' ###################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$hiring.dt 
#'
#' ## generate single reduct
#' res.1 <- FS.permutation.heuristic.reduct.RST(decision.table,  permutation = NULL, 
#'                         decisionIdx = 5)
#' 
#' ## generate new decision table according to the reduct
#' new.decTable <- SF.applyDecTable(decision.table, res.1) 
#' @export
FS.permutation.heuristic.reduct.RST <- function(decision.table, permutation = NULL, decisionIdx = ncol(decision.table), ...){

	## get the data 
	names.attrs = colnames(decision.table)
	
	if (is.null(permutation)) {
		## shuffle the attributes
		permutation = sample((1:ncol(decision.table))[-decisionIdx])
	}	
	else if (permutation == FALSE) {
		## without shuffling
		permutation = (1:ncol(decision.table))[-decisionIdx]
	}
  
	## Initialization
	endFlag = FALSE
	iteration = 1	
	
	## check consistency/certainty which is objects included in lower approximations
	## iteration refers to the number of selected variables to be superreducts
	while (!(sum(duplicated(decision.table[permutation[1:iteration]])) == sum(duplicated(decision.table[c(permutation[1:iteration],decisionIdx)])))) {
		iteration = iteration + 1
    if(iteration > length(permutation)) 
      stop("Inconsistent decision table - this method is currently implemented only for consistent data.\n\t\tTry a different reduct computation algorithm.")
	}
	
	## elimating process to get reducts
	redIdxs = permutation[1:iteration]
  if(iteration == 1) endFlag = TRUE
	while (!endFlag) {
		  if (sum(duplicated(decision.table[redIdxs[-iteration]])) == sum(duplicated(decision.table[c(redIdxs[-iteration],decisionIdx)]))) {
				redIdxs = redIdxs[-iteration]
		  }
		  iteration = iteration - 1
		  if (iteration == 0 | length(redIdxs) == 1) {
				endFlag = TRUE
    	  }
	}
	
	## get reduct
	reduct <- redIdxs[order(redIdxs)]
	names(reduct) <- names.attrs[reduct]
	
	## construct class
	mod <- list(reduct = reduct, type.method = "permutation.heuristic", 
	            type.task = "feature selection", model = "RST")
				
	class.mod <- ObjectFactory(mod, classname = "FeatureSubset")	
	return(class.mod)  	
}

#' This is a function used for implementing a greedy heuristic method for feature selection based on RST. 
#' 
#' In this function, we have provided some quality measures of subsets of attributes. The measure are important to
#' determine the quality of a subset to be a reduct. For example, \code{X.entropy} is a measure of information gain. 
#' We select one of the measures by assigning the \code{qualityF} parameter.
#'
#' Additionally, this function has implemented \eqn{\epsilon}-approximate reducts. It means that 
#' the method attempts to approximate the original decision model by producing an approximate reduct which is
#' subset of attributes. The \eqn{\epsilon}-approximate can be defined as
#'
#' \eqn{Disc_{\mathcal{A}}(B) \ge (1 - \epsilon)Disc_{\mathcal{A}}(A)}
#'
#' where \eqn{Disc_{\mathcal{A}}(B)} is the discernibility measure of attributes \eqn{B} in decision table \eqn{\mathcal{A}}
#' and \eqn{\epsilon} is numeric value between 0 and 1.
#' A lot of monographs provide comprehensive explanations about this topics, for example 
#' (Janusz and Stawicki, 2011; Slezak, 2002; Wroblewski, 2001) which are used as the references of this function.
#' 
#' Additionally, \code{\link{SF.applyDecTable}} has been provided to generate new decision table. 
#'
#' @title The greedy heuristic algorithm for determining a reduct
#
#' @param decision.table a \code{"DecisionTable"} class representing the decision table. See \code{\link{SF.asDecisionTable}}.
#' @param decisionIdx an integer value representing an index of the decision attribute. 
#' @param qualityF a function representing the quality of subset of attributes. In this package, the following functions have been included:
#'        \itemize{
#'        \item \code{X.entropy}: See \code{\link{X.entropy}}.
#'        \item \code{X.gini}: See \code{\link{X.gini}}.
#'        \item \code{X.nOfConflicts}: See \code{\link{X.nOfConflicts}}.
#'        \item \code{X.nOfConflictsLog}: See \code{\link{X.nOfConflictsLog}}.
#'        \item \code{X.nOfConflictsSqrt}: See \code{\link{X.nOfConflictsSqrt}}.
#'        }
#' @param nAttrs a vector representing indexes of conditional attributes.
#' @param epsilon a numeric value between [0, 1] representing whether it is using approximate reducts or not.
#' @param ... other parameters.
#' @seealso \code{\link{FS.quickreduct.RST}} and \code{\link{FS.reduct.computation}}.
#' @return A class \code{"FeatureSubset"} that contains the following components:
#' \itemize{
#' \item \code{reduct}: a list representing a single reduct. In this case, it could be a superreduct or just a subset of features.
#' \item \code{type.method}: a string representing the type of method which is \code{"greedy.heuristic"}.
#' \item \code{type.task}: a string showing the type of task which is \code{"feature selection"}.
#' \item \code{model}: a string representing the type of model. In this case, it is \code{"RST"} which means rough set theory.
#' }  
#' @references
#' A. Janusz and S. Stawicki, "Applications of Approximate Reducts to the Feature Selection Problem", 
#' Proceedings of International Conference on Rough Sets and Knowledge Technology ({RSKT}), vol. 6954, p. 45 - 50 (2011).
#'
#' D. Slezak, "Approximate Entropy Reducts", Fundamenta Informaticae, vol. 53, no. 3 - 4, p. 365 - 390 (2002).
#'
#' J. Wroblewski, "Ensembles of Classifiers Based on Approximate Reducts", Fundamenta Informaticae, vol. 47, no. 3 - 4, p. 351 - 360 (2001).
#'
#' @examples
#' ###################################################
#' ## Example 1: Evaluate reduct and generate 
#' ##            new decision table
#' ###################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$hiring.dt 
#'
#' ## evaluate a single reduct
#' res.1 <- FS.greedy.heuristic.reduct.RST(decision.table, qualityF = X.entropy, 
#'                                         epsilon = 0.0)
#' 
#' ## generate a new decision table corresponding to the reduct
#' new.decTable <- SF.applyDecTable(decision.table, res.1)  
#' @export
FS.greedy.heuristic.reduct.RST <- function(decision.table, decisionIdx = ncol(decision.table), 
                                           qualityF = X.gini, nAttrs = NULL, 
                                           epsilon = 0.0, ...)  {
	## get the data 
	toRmVec = decisionIdx
	attrIdxVec = (1:ncol(decision.table))[-toRmVec]
	
	if (!is.null(nAttrs)) {
		if (nAttrs == 0 || nAttrs > ncol(decision.table) - 1) {
			stop("There is something wrong with data (too little attributes?) or the parameter nAttrs has a wrong value.")
		}
		tmpAttrSub = sample(attrIdxVec, min(nAttrs, length(attrIdxVec)))
	}	else tmpAttrSub = attrIdxVec
  
	if (epsilon >= 1 || epsilon < 0) {
		stop("Wrong value of the parameter epsilon. It must be within [0,1) interval.")
	}
	
	dummyAttr = rep(1,nrow(decision.table))
	clsContingencyTab = as.matrix(table(dummyAttr, decision.table[[decisionIdx]]))
	decisionChaos = sum(apply(clsContingencyTab, 1, qualityF)*(rowSums(clsContingencyTab)/nrow(decision.table)))
	attrScoresVec = sapply(decision.table[tmpAttrSub], qualityGain, 
                         decision.table[[decisionIdx]], dummyAttr, decisionChaos, chaosFunction = qualityF)
	tmpBestIdx = which.max(attrScoresVec)
	rm(dummyAttr, clsContingencyTab)
  
	selectedAttrIdxVec  = tmpAttrSub[tmpBestIdx]
	attrVec = decision.table[[selectedAttrIdxVec]]
	attrIdxVec = (1:ncol(decision.table))[-c(selectedAttrIdxVec, toRmVec)]
  
	endFlag = F
	iteration = 1
	clsContingencyTab = as.matrix(table(do.call(paste, decision.table[-decisionIdx]), decision.table[[decisionIdx]]))
	totalChaos = sum(apply(clsContingencyTab, 1, qualityF)*(rowSums(clsContingencyTab)/nrow(decision.table))) 
	totalDependencyInData = decisionChaos - totalChaos
	approxThereshold = (1 - epsilon)*totalDependencyInData
	rm(clsContingencyTab)
  
	while (!endFlag) {
		clsContingencyTab = as.matrix(table(attrVec, decision.table[[decisionIdx]]))
		tmpChaos = sum(apply(clsContingencyTab, 1, qualityF)*(rowSums(clsContingencyTab)/nrow(decision.table)))
		tmpDependencyInData = decisionChaos - tmpChaos
		rm(clsContingencyTab)
		if (approxThereshold <= tmpDependencyInData) {
			endFlag = T
		}	else {
			if (!is.null(nAttrs)) {
				tmpAttrSub = sample(attrIdxVec, min(nAttrs, length(attrIdxVec)))
			}	else tmpAttrSub = attrIdxVec
			attrScoresVec = sapply(decision.table[tmpAttrSub], qualityGain, 
                             decision.table[[decisionIdx]], attrVec, tmpChaos, chaosFunction = qualityF)
			tmpBestIdx = which.max(attrScoresVec)
			selectedAttrIdxVec[iteration + 1] = tmpAttrSub[tmpBestIdx]
			attrVec = do.call(paste, list(decision.table[[tmpAttrSub[tmpBestIdx]]], attrVec))
			attrIdxVec = (1:ncol(decision.table))[-c(selectedAttrIdxVec, toRmVec)]
			iteration = iteration + 1
			rm(tmpAttrSub, attrScoresVec, tmpBestIdx)
		}
	}
  
	if (iteration > 1) {
		endFlag = F
		iteration = iteration - 1
		while (!endFlag) {
			clsContingencyTab = as.matrix(table(do.call(paste, decision.table[selectedAttrIdxVec[-iteration]]), decision.table[[decisionIdx]]))
			tmpChaos = sum(apply(clsContingencyTab, 1, qualityF)*(rowSums(clsContingencyTab)/nrow(decision.table))) 
			tmpDependencyInData = decisionChaos - tmpChaos
			if (approxThereshold <= tmpDependencyInData) {
				selectedAttrIdxVec = selectedAttrIdxVec[-iteration]
			}
			iteration = iteration - 1
			if (iteration == 0) endFlag = T
		}
	}
  
	reduct <- selectedAttrIdxVec[order(selectedAttrIdxVec)]
	names(reduct) <- colnames(decision.table)[reduct]
  
	## construct class
	mod <- list(reduct = reduct, type.method = "greedy.heuristic", 
	            type.task = "feature selection", model = "RST")
				
	class.mod <- ObjectFactory(mod, classname = "FeatureSubset")	
	return(class.mod)  	
}

#' It is a wrapper function aimed to calculate a superreduct (i.e., a subset of features). 
#' 
#' There exist three methods considered in this function as follows: 
#' \itemize{
#' \item \code{"greedy.heuristic.superreduct"}: it is a greedy heuristic method which employs several quality measurements based on RST. 
#'            See \code{\link{FS.greedy.heuristic.superreduct.RST}}.
#' \item \code{"quickreduct.frst"}: it is a feature selection function based on the fuzzy QuickReduct algorithm on FRST.
#'            See \code{\link{FS.quickreduct.FRST}}.
#' \item \code{"quickreduct.rst"}: it is a feature selection function based on the RST QuickReduct algorithm.
#'            See \code{\link{FS.quickreduct.RST}}.
#' }
#' These methods can be selected by assigning the parameter \code{method}. 
#' Additionally, \code{\link{SF.applyDecTable}} has been provided to generate the new decision table. 
#'
#' @title The superreduct computation based on RST and FRST
#'
#' @param decision.table a \code{"DecisionTable"} class representing the decision table. See \code{\link{SF.asDecisionTable}}.
#' @param method a string representing the type of methods. See in Section \code{Details}.
#' @param ... other parameters corresponding to the chosen \code{method}.
#' @seealso \code{\link{FS.quickreduct.RST}}.
#' @return A class \code{"FeatureSubset"}. 
#'
#'       See \code{\link{FS.quickreduct.RST}} or \code{\link{FS.quickreduct.FRST}}.
#' @examples
#' ###############################################################
#' ## Example 1: generate reduct and new decision table using RST
#' ###############################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$hiring.dt 
#'
#' ## generate single superreduct
#' res.1 <- FS.feature.subset.computation(decision.table, 
#'                   method = "quickreduct.rst")
#' 
#' ## generate new decision table according to the reduct
#' new.decTable <- SF.applyDecTable(decision.table, res.1) 
#'
#' ###############################################################
#' ## Example 2: generate reduct and new decision table using FRST
#' ###############################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$housing7.dt 
#'
#' ## generate single superreduct
#' res.2 <- FS.feature.subset.computation(decision.table, 
#'                   method = "quickreduct.frst")
#' 
#' ## generate new decision table according to the reduct
#' new.decTable <- SF.applyDecTable(decision.table, res.2) 
#' @export 
FS.feature.subset.computation <- function(decision.table, method = "greedy.heuristic.superreduct", ...) {
  
  if (!(method %in% c("greedy.heuristic.superreduct", "quickreduct.rst",
                      "quickreduct.frst"))) {
    stop("Unrecognized attribute reduction method.")
  }
  
  if(!inherits(decision.table, "DecisionTable")) {
    stop("Provided data should inherit from the \'DecisionTable\' class.")
  }
  
  nominal.att <- attr(decision.table, "nominal.attrs")
  if(!all(nominal.att) && !(method %in% "quickreduct.frst")) stop("Discretize attribures before computing RST reducts.")
  
  if(is.null(attr(decision.table, "decision.attr"))) stop("A decision attribute is not indicated.")
  else decIdx = attr(decision.table, "decision.attr")
  
  superreduct = switch(method,  
                       greedy.heuristic.superreduct = FS.greedy.heuristic.superreduct.RST(decision.table, decisionIdx = decIdx, ...),
                       quickreduct.rst = FS.quickreduct.RST(decision.table, ...),
                       quickreduct.frst = FS.quickreduct.FRST(decision.table, ...) )
  
  return(superreduct)
}

#' This is a function for implementing the QuickReduct algorithm for feature selection based
#' on RST proposed by (Shen and Chouchoulas, 2000). The algorithm produces only one feature subset that could be a superreduct. 
#' 
#' This algorithm considers the dependency degree (see \code{\link{A.Introduction-RoughSets}}) 
#' of the addition of each attribute to the current reduct candidate. Then the best candidate will be chosen. 
#' This process continues until the dependency of the subset equals to the dependency of the full dataset. 
#'
#' Additionally, in \code{control} parameter, we provide one component which is 
#' \code{randomize}. It has a boolean value: \code{TRUE} or \code{FALSE} that means we want to perform 
#' quickreduct by evaluating attributes randomly or all attributes in decision table.
#'
#' It should be noted that this function does not give the new decision table directly. 
#' The other additional function called \code{\link{SF.applyDecTable}} is used to produce new decision table based on 
#' information about the reduct from this function.
#'
#' @title QuickReduct algorithm based on RST
#' 
#' @param decision.table a \code{"DecisionTable"} class representing the decision table. See \code{\link{SF.asDecisionTable}}. 
#' @param control other parameters. It contains the following component:
#'        \itemize{
#'        \item \code{randomize}: it has a boolean value. For the detailed description, see in Section \code{Details}.
#'              The default value is \code{FALSE}.
#'        }
#' @param ... other parameters.
#' @seealso \code{\link{FS.quickreduct.FRST}}
#' @return A class \code{"FeatureSubset"} that contains the following components:
#' \itemize{
#' \item \code{reduct}: a list representing single reduct. In this case, it could be super reduct or just subset of feature.
#' \item \code{type.method}: a string representing a type of method which is \code{"quickreduct"}.
#' \item \code{type.task}: a string showing type of task which is \code{"feature selection"}.
#' \item \code{model}: a string representing a type of model. In this case, it is \code{"RST"} which means rough set theory.
#' } 
#' @references
#' Q. Shen and A. Chouchoulas, "A Modular Approach to Generating Fuzzy Rules with Reduced Attributes for the Monitoring of Complex Systems",
#' Engineering Applications of Artificial Intelligence, vol. 13, p. 263 - 278 (2000).
#' 
#' @examples
#' ###################################################
#' ## Example 1: Evaluate reduct and generate 
#' ##            new decision table
#' ###################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$hiring.dt 
#'
#' ## evaluate single reduct
#' res.1 <- FS.quickreduct.RST(decision.table)
#' 
#' ## generate new decision table according to the reduct
#' new.decTable <- SF.applyDecTable(decision.table, res.1)
#'
#' @export
FS.quickreduct.RST <- function(decision.table, control = list(), ...){
	
	names.attrs <-  names(attr(decision.table, "desc.attrs"))	
	super.reduct <- quickreduct.alg(decision.table, type.method = "quickreduct.RST", control = control)
    names(super.reduct) = names.attrs[super.reduct]
	mod <- list(reduct = super.reduct, type.method = "quickreduct", 
	            type.task = "feature selection", model = "RST")
				
	class.mod <- ObjectFactory(mod, classname = "FeatureSubset")	
	return(class.mod)  
}

#' It is used to get the feature subset (superreduct) based on the greedy heuristic algorithm 
#' employing some quality measurements. Regarding the quality measurements, the detailed description can be seen in \code{\link{FS.greedy.heuristic.reduct.RST}}.
#' 
#' @title The greedy heuristic method for determining superreduct based on RST
#' @param decision.table a \code{"DecisionTable"} class representing decision table. See \code{\link{SF.asDecisionTable}}. 
#' @param decisionIdx a integer value representing an index of decision attribute. 
#' @param qualityF a function calculating quality on a set of attributes. 
#'
#'        See \code{\link{FS.greedy.heuristic.reduct.RST}}.
#' @param nAttrs a vector representing indexes of conditional attributes.
#' @param ... other parameters.
#' @seealso \code{\link{FS.quickreduct.RST}} and \code{\link{FS.feature.subset.computation}}.
#' @return A class \code{"FeatureSubset"} that contains the following components:
#' \itemize{
#' \item \code{reduct}: a list representing a single reduct. In this case, it could be a superreduct or just a subset of features.
#' \item \code{type.method}: a string representing the type of method which is \code{"greedy.heuristic.superreduct"}.
#' \item \code{type.task}: a string showing the type of task which is \code{"feature selection"}.
#' \item \code{model}: a string representing the type of model. In this case, it is \code{"RST"} which means rough set theory.
#' }  
#' @references
#' A. Janusz and S. Stawicki, "Applications of Approximate Reducts to the Feature Selection Problem", 
#' Proceedings of International Conference on Rough Sets and Knowledge Technology ({RSKT}), vol. 6954, p. 45 - 50 (2011).
#'
#' D. Slezak, "Approximate Entropy Reducts", Fundamenta Informaticae, vol. 53, no. 3 - 4, p. 365 - 390 (2002).
#'
#' J. Wroblewski, "Ensembles of Classifiers Based on Approximate Reducts", Fundamenta Informaticae, vol. 47, no. 3 - 4, p. 351 - 360 (2001).
#'
#' @examples
#' ###################################################
#' ## Example 1: Evaluate reduct and generate 
#' ##            new decision table
#' ###################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$hiring.dt 
#'
#' ## evaluate single reduct
#' res.1 <- FS.greedy.heuristic.superreduct.RST(decision.table, qualityF = X.nOfConflictsSqrt)
#' 
#' ## generate new decision table according to the reduct
#' new.decTable <- SF.applyDecTable(decision.table, res.1)
#' @export
FS.greedy.heuristic.superreduct.RST <- function(decision.table, decisionIdx = ncol(decision.table), 
                                           qualityF = X.gini, nAttrs = NULL, ...)  {
	toRmVec = decisionIdx
	attrIdxVec = (1:ncol(decision.table))[-toRmVec]
	
	if (!is.null(nAttrs)) {
		if(nAttrs == 0 || nAttrs > ncol(decision.table) - 1) {
			stop("There is something wrong with data (too little attributes?) or the parameter nAttrs has a wrong value.")
		}
		tmpAttrSub = sample(attrIdxVec, min(nAttrs, length(attrIdxVec)))
	}  else tmpAttrSub = attrIdxVec
  
	dummyAttr = rep(1,nrow(decision.table))
	clsContingencyTab = as.matrix(table(dummyAttr, decision.table[[decisionIdx]]))
	decisionChaos = sum(apply(clsContingencyTab, 1, qualityF)*(rowSums(clsContingencyTab)/nrow(decision.table)))
	attrScoresVec = sapply(decision.table[tmpAttrSub], qualityGain, 
                         decision.table[[decisionIdx]], dummyAttr, decisionChaos, chaosFunction = qualityF)
	tmpBestIdx = which.max(attrScoresVec)
	rm(dummyAttr, clsContingencyTab)
  
	selectedAttrIdxVec  = tmpAttrSub[tmpBestIdx]
	attrVec = decision.table[[selectedAttrIdxVec]]
	attrIdxVec = (1:ncol(decision.table))[-c(selectedAttrIdxVec, toRmVec)]
  
	endFlag = F
	iteration = 1
	clsContingencyTab = as.matrix(table(do.call(paste, decision.table[-decisionIdx]), decision.table[[decisionIdx]]))
	totalChaos = sum(apply(clsContingencyTab, 1, qualityF)*(rowSums(clsContingencyTab)/nrow(decision.table))) 
	totalDependencyInData = decisionChaos - totalChaos
	rm(clsContingencyTab)
  
	while (!endFlag) {
		clsContingencyTab = as.matrix(table(attrVec, decision.table[[decisionIdx]]))
		tmpChaos = sum(apply(clsContingencyTab, 1, qualityF)*(rowSums(clsContingencyTab)/nrow(decision.table)))
		tmpDependencyInData = decisionChaos - tmpChaos
		rm(clsContingencyTab)
		if (totalDependencyInData <= tmpDependencyInData) endFlag = T
		else {
			if (!is.null(nAttrs)) {
				tmpAttrSub = sample(attrIdxVec, min(nAttrs, length(attrIdxVec)))
			}	else tmpAttrSub = attrIdxVec
			attrScoresVec = sapply(decision.table[tmpAttrSub], qualityGain, 
                             decision.table[[decisionIdx]], attrVec, tmpChaos, chaosFunction = qualityF)
			tmpBestIdx = which.max(attrScoresVec)
			selectedAttrIdxVec[iteration + 1] = tmpAttrSub[tmpBestIdx]
			attrVec = do.call(paste, list(decision.table[[tmpAttrSub[tmpBestIdx]]], attrVec))
			attrIdxVec = (1:ncol(decision.table))[-c(selectedAttrIdxVec, toRmVec)]
			iteration = iteration + 1
			rm(tmpAttrSub, attrScoresVec, tmpBestIdx)
		}
	}
  
	## get super reduct
	super.reduct <- selectedAttrIdxVec[order(selectedAttrIdxVec)]
	names(super.reduct) = colnames(decision.table)[super.reduct]
	
	## Construct class
	mod <- list(reduct = super.reduct, type.method = "greedy.heuristic.superreduct", 
	            type.task = "feature selection", model = "RST")
				
	class.mod <- ObjectFactory(mod, classname = "FeatureSubset")	
	return(class.mod)  
}


#' It is a function implementing the fuzzy QuickReduct algorithm 
#' for feature selection based on FRST. 
#' The fuzzy QuickReduct is a modification of QuickReduct based on RST (see \code{\link{FS.quickreduct.RST}}). 
#' 
#' In this function, we provide an algorithm proposed by 
#'(Jensen and Shen, 2002) which is fuzzy QuickReduct. Then, the algorithm has been modified by (Bhatt and Gopal, 2005) to improve stopping criteria.  
#' This function is aimed to implement both algorithms. These algorithms can be executed by assigning the parameter \code{type.QR} 
#' with \code{"fuzzy.QR"} and \code{"modified.QR"} for fuzzy quickreduct and modified fuzzy quickreduct 
#' algorithms, respectively. Additionally, in the \code{control} parameter, we provide one component which is 
#' \code{randomize} having boolean values: \code{TRUE} or \code{FALSE}. \code{randomize = TRUE} means that 
#' we evaluate some (or not all) attributes randomly along iteration. It will be useful if we have a large number of attributes 
#' in a decision table.
#'
#' In this function, we have considered many approaches of the lower and upper approximations.
#' The following list shows considered methods and their descriptions. Additionally, those approaches can be executed by
#' assigning the following value to the parameter \code{type.method}.
#' \itemize{
#'    \item \code{"fuzzy.dependency"}: It is based on the degree of dependency using the implication/t-norm model approximation (Jensen and Shen, 2009).   
#'                The detailed concepts about this approximation have been explained in \code{\link{B.Introduction-FuzzyRoughSets}} 
#'                and 
#'
#'                \code{\link{BC.LU.approximation.FRST}}.
#'    \item \code{"fuzzy.boundary.reg"}: It is based on the fuzzy boundary region proposed by (Jensen and Shen, 2009).
#'                This algorithm introduced the usage of the total uncertainty degree \eqn{\lambda_B(Q)} 
#'                for all concepts of feature subset \eqn{B} and decision attribute \eqn{Q}. 
#'                The total uncertainty degree is used as a parameter to select appropriate features. 
#'   \item \code{"vqrs"}: It is based on vaquely quantified rough set (VQRS) 
#'                proposed by (Cornelis and Jensen, 2008). See also \code{\link{BC.LU.approximation.FRST}}. 
#'   \item \code{"owa"}: Based on ordered weighted average (OWA) based fuzzy rough set, (Cornelis et al, 2010) proposed 
#'                the degree of dependency as a parameter employed in the algorithm to select appropriate features. The explanation 
#'                about lower and upper approximations based on OWA can be found in \code{\link{BC.LU.approximation.FRST}}.
#'   \item \code{"rfrs"}: It is based on degree of dependency that is obtained by performing 
#'                the robust fuzzy rough sets proposed by (Hu et al, 2012). 
#'                The detailed concepts about this approximation have been explained in \code{\link{BC.LU.approximation.FRST}}. 
#   \item \code{"sfrs"}: It is based on degree of dependency that is obtained by performing 
#                soft fuzzy rough sets (SFRS) proposed by (Hu et al, 2010). 
#                The detailed concepts about this approximation have been explained in \code{\link{BC.LU.approximation.FRST}}. 
#                Additionally, it should be noted that this method is good in selecting features on 
#                dataset containing continuous conditional features only. 
#'   \item \code{"min.positive.reg"}: Based on measure introduced in (Cornelis et al, 2010) which considers the most problematic element in 
#'              the positive region, defined using the implicator/t-norm model.
#'   \item \code{"fvprs"}: It is based on degree of dependency proposed by (Zhao et al, 2009). 
#'                The degree is obtained by using fuzzy lower approximation based on 
#'                fuzzy variable precision rough set model. 
#'   \item \code{"fuzzy.discernibility"}: This approach attempts to combine the the decision-relative discernibility matrix 
#'               and the fuzzy QuickReduct algorithm. (Jensen and Shen, 2009) introduced a measurement which is the degree of satisfaction to select the attributes.
#'   \item \code{"beta.pfrs"}: Based on \eqn{\beta}-precision fuzzy rough sets (\eqn{\beta}-PFRS) proposed by (Salido and Murakami, 2003),
#'                the degree of dependency as a parameter employed in the algorithm to select appropriate features. The explanation 
#'                about lower and upper approximations based on \eqn{\beta}-PFRS can be found in \code{\link{BC.LU.approximation.FRST}}.
#' } 
#'
#' It should be noted that the parameter \code{type.method} is related to parameter \code{control}. 
#' In other words, we only set the components in the \code{control} parameter that related to the chosen type of method. 
#' The following is a list showing the components of \code{control} needed by each type of methods.
#' \itemize{
#' \item \code{type.method = "fuzzy.dependency"}:
#'
#' \code{control <- list(t.implicator, type.relation, type.aggregation)}
#'
#' \item \code{type.method = "fuzzy.boundary.reg"}:
#'
#' \code{control <- list(t.implicator, type.relation, type.aggregation)}
#'
#' \item \code{type.method = "vqrs"}:
#'
#' \code{control <- list(alpha, q.some, q.most, type.aggregation)}
#'
#' \item \code{type.method = "owa"}:
#'
#' \code{control <- list(t.implicator, type.relation, m.owa, type.aggregation)}
#' 
# \item \code{type.method = "sfrs"}:
# 
# \code{control <- list(penalty.fact, type.aggregation)}
#
#' \item \code{type.method = "rfrs"}:
#'
#' \code{control <- list(t.implicator, type.relation, type.rfrs,}
#'
#'                 \code{k.rfrs, type.aggregation)}
#'
#' \item \code{type.method = "min.positive.reg"}:
#'
#' \code{control <- list(alpha, t.implicator, type.relation, type.aggregation)}
#'
#' \item \code{type.method = "fuzzy.discernibility"}: 
#' 
#' \code{control <- list(alpha, t.implicator, type.relation, type.aggregation)}
#'
#' \item \code{type.method = "fvprs"}:
#'
#' \code{control <- list(alpha.precision, t.implicator, type.relation, type.aggregation)}
#'
#' \item \code{type.method = "beta.pfrs"}:
#'
#' \code{control <- list(t.implicator, type.relation, beta.quasi, type.aggregation)}
#' }
#' The descriptions of each component can be seen in the documentation of the \code{control} parameter. 
#'
#' It should be noted that this function does not give the new decision table directly. 
#' An additional function called \code{\link{SF.applyDecTable}} is used to produce new decision table based on 
#' information about the reduct from this function. See Section \code{Examples}.
#'
#' @title The fuzzy QuickReduct algorithm based on FRST
#' 
#' @param decision.table a \code{"DecisionTable"} class representing the decision table. See \code{\link{SF.asDecisionTable}}. 
#' @param type.method a string representing the type of methods. 
#'         The complete description can be found in Section \code{Details}.
#' @param type.QR a string expressing the type of QuickReduct algorithm which is one of the two following algorithms:
#'         \itemize{
#'         		\item \code{"fuzzy.QR"}: it is the original fuzzy rough QuickReduct algorithm based on (Jensen and Shen, 2002).
#'         		\item \code{"modified.QR"}: it is the modified QuickReduct algorithm based on (Bhatt and Gopal, 2005).
#'         }
#' @param control a list of other parameters as follows. 
#'         \itemize{
#'          \item \code{type.aggregation}: a type of aggregation operator. See \code{\link{BC.IND.relation.FRST}}. 
#'          \item \code{t.implicator}: a type of implicator function. See \code{\link{BC.LU.approximation.FRST}}.
#'                The default value is \code{"lukasiewicz"}.
#'          \item \code{type.relation}: a type of indiscernibility relation. See \code{\link{BC.IND.relation.FRST}}. 
#'                 The default value is \code{type.relation = c("tolerance", "eq.3")}.
#'          \item \code{alpha}: a real number between 0 and 1 expressing a threshold value or stopping criterion. 
#'                 The following methods use the parameter: \code{"vqrs"}, 
#'
#'                 \code{"min.positive.reg"}, and \code{"fuzzy.discernibility"}.
#'                 The default value is 0.95.
#'          \item \code{alpha.precision}: a real number between 0 and 1 expressing variable precision (\eqn{\alpha}) for \code{"fvprs"}.
#'                 See \code{\link{BC.LU.approximation.FRST}}. The default value is 0.05.  
#'          \item \code{q.some}: a pair of numeric values for the alpha and beta parameter of VQRS for the quantifier \code{some}. 
#'                 The default value is \code{q.some = c(0.1, 0.6)}. 
#'
#'                 See \code{\link{BC.LU.approximation.FRST}}. 
#'          \item \code{q.most}: a pair of numeric values for the alpha and beta parameter of VQRS for the quantifier \code{most}.
#'                 The default value is \code{q.most = c(0.2, 1)}. 
#'
#'                 See \code{\link{BC.LU.approximation.FRST}}.
#'          \item \code{m.owa}: a numeric value to define the parameter in OWA. The default value is the mean number of objects.
#          \item \code{penalty.fact}: a real number representing penalty factor on soft fuzzy rough sets. 
#                 The default value is 0.8. See \code{\link{BC.LU.approximation.FRST}}.
#'          \item \code{type.rfrs}: a type of robust fuzzy rough sets.
#'
#'                 The default is \code{type.rfrs = "k.trimmed.min")}. 
#'
#'                 See \code{\link{BC.LU.approximation.FRST}}.
#'          \item \code{k.rfrs}: a value between 0 and length of data representing index of considered data. 
#'                 The default is \code{k.rfrs = round(0.5*nrow(decision.table))}.
#'                See \code{\link{BC.LU.approximation.FRST}}.
#'          \item \code{beta.quasi}: a number between 0 and 1 representing \eqn{\beta}-precision t-norms and t-conorms.
#'                    The default value is 0.05.
#'          \item \code{randomize}: a boolean value to define whether selecting attributes randomly or not. For more detail, 
#'                see in Section \code{Details}. The default value is \code{FALSE}.
#'          }
#'         It should be noted that instead of supplying all the above parameters, we only set  
#'         those parameters needed by the considered method. See in Section \code{Details}. 
#'         Also, we provide some examples to illustrate how the parameters are used.
#'  
#' @param ... other parameters.
#' @seealso \code{\link{FS.quickreduct.RST}} and \code{\link{FS.feature.subset.computation}}.
#' @return A class \code{"FeatureSubset"} that contains the following components:
#' \itemize{
#' \item \code{reduct}: a list representing a single reduct. In this case, it could be a superreduct or just a subset of feature.
#' \item \code{type.method}: a string representing the type of method. 
#' \item \code{type.task}: a string showing the type of task which is \code{"feature selection"}.
#' \item \code{model}: a string representing the type of model. In this case, it is \code{"FRST"} which means fuzzy rough set theory.
#' } 
#' @references
#' C. Cornelis, G. Hurtado Martin, R. Jensen, and D. Slezak, 
#' "Feature Selection with Fuzzy Decision Reducts", Information Sciences, vol. 180, no. 2, p. 209 - 224 (2010).
#' 
#' C. Cornelis, N. Verbiest, and R. Jensen, "Ordered Weighted Average Based Fuzzy Rough Sets",
#' Proceedings of the 5th International Conference on Rough Sets and Knowledge Technology (RSKT 2010),
#' p. 78 - 85 (2010).
#' 
#' C. Cornelis and R. Jensen, "A Noise-tolerant Approach to Fuzzy-rough Feature Selection", 
#' Proceedings of the 2008 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2008),
#' p. 1598 - 1605 (2008).
#'
#' J. M. F. Salido and S. Murakami, "Rough Set Analysis of a General Type of Fuzzy Data
#' Using Transitive Aggregations of Fuzzy Similarity Relations", 
#' Fuzzy Sets Syst., vol. 139, p. 635 - 660 (2003).
#'
# Q. Hu, S. An, and D. Yu, "Soft Fuzzy Rough Sets for Robust Feature Evaluation and Selection",
# Information Sciences, vol. 180, p. 4384 - 4400 (2010).
#
#' Q. Hu, L. Zhang, S. An, D. Zhang, and D. Yu, "On Robust Fuzzy Rough Set Models",
#' IEEE Trans. on Fuzzy Systems, vol. 20, no. 4, p. 636 - 651 (2012).
#' 
#' R. B. Bhatt and M. Gopal, "On Fuzzy-rough Sets Approach to Feature Selection", 
#' Pattern Recognition Letters, vol. 26, no. 7, p. 965 - 975 (2005).
#'
#' R. Jensen and Q. Shen, "Fuzzy-rough Sets for Descriptive Dimensionality Reduction", 
#' In: Proceedings of IEEE International Conference on Fuzzy System, FUZZ-IEEE, p. 29 - 34 (2002).
#'
#' R. Jensen and Q. Shen, "New Approaches to Fuzzy-rough Feature Selection", 
#' IEEE Transactions on Fuzzy Systems, vol. 17, no. 4, p. 824 - 838 (2009).
#' 
#' S. Y. Zhao, E. C. C. Tsang, and D. G. Chen, 
#' "The Model of Fuzzy Variable Precision Rough Sets",
#' IEEE Trans. Fuzzy Systems, vol. 17, no. 2,
#' p. 451 - 467 (2009). 
#'
#' @examples
#' ##########################################################
#' ## Example 1: Dataset containing nominal values on all attributes
#' ##########################################################
#'
#' data(RoughSetData)
#' decision.table <- RoughSetData$housing7.dt  
#'
#' ########## using fuzzy lower approximation ##############
#' control <- list(t.implicator = "lukasiewicz", type.relation = c("tolerance", "eq.1"), 
#'                type.aggregation = c("t.tnorm", "lukasiewicz"))
#' reduct.1 <- FS.quickreduct.FRST(decision.table, type.method = "fuzzy.dependency", 
#'                             type.QR = "fuzzy.QR", control = control)
#'
#' ########## using fuzzy boundary region ##############
#' \dontrun{control <- list(t.implicator = "lukasiewicz", type.relation = c("tolerance", "eq.1"), 
#'                 type.aggregation = c("t.tnorm", "lukasiewicz"))
#' reduct.2 <- FS.quickreduct.FRST(decision.table, type.method = "fuzzy.boundary.reg", 
#'                             type.QR = "fuzzy.QR", control = control)
#' 
#' ########## using vaguely quantified rough sets (VQRS) #########
#' control <- list(alpha = 0.9, q.some = c(0.1, 0.6), q.most = c(0.2, 1), 
#'                 type.aggregation = c("t.tnorm", "lukasiewicz")) 
#' reduct.3 <- FS.quickreduct.FRST(decision.table, type.method = "vqrs", 
#'                             type.QR = "fuzzy.QR", control = control)
#'
#' ########## ordered weighted average (OWA) #########
#' control <- list(t.implicator = "lukasiewicz", type.relation = c("tolerance", "eq.1"), 
#'                 m.owa = 3, type.aggregation = c("t.tnorm","lukasiewicz")) 
#' reduct.4 <- FS.quickreduct.FRST(decision.table, type.method = "owa", 
#'                             type.QR = "fuzzy.QR", control = control)
#'
#' ########## robust fuzzy rough sets (RFRS) #########
#' control <- list(t.implicator = "lukasiewicz", type.relation = c("tolerance", "eq.1"), 
#'                type.rfrs = "k.trimmed.min", type.aggregation = c("t.tnorm", "lukasiewicz"), 
#'                k.rfrs = 0) 
#' reduct.5 <- FS.quickreduct.FRST(decision.table, type.method = "rfrs", 
#'                             type.QR = "fuzzy.QR", control = control)
#'
#' ########## using min positive region (delta) ###########
#' control <- list(alpha = 1, t.implicator = "lukasiewicz", 
#'                 type.relation = c("tolerance", "eq.1"), type.aggregation = 
#'                                 c("t.tnorm", "lukasiewicz"))
#' reduct.6 <- FS.quickreduct.FRST(decision.table, type.method = "min.positive.reg", 
#'                             type.QR = "fuzzy.QR", control = control)
#'
#' ########## using FVPRS approximation ##############
#' control <- list(alpha.precision = 0.05, t.implicator = "lukasiewicz",
#'                type.aggregation = c("t.tnorm", "lukasiewicz"), 
#'                type.relation = c("tolerance", "eq.1"))
#' reduct.7 <- FS.quickreduct.FRST(decision.table, type.method = "fvprs", 
#'                             type.QR = "fuzzy.QR", control = control)
#'
# ########## using SFRS approximation ##############
# control <- list(penalty.fact = 1, type.aggregation = c("t.tnorm", "lukasiewicz"))
# reduct.8 <- FS.quickreduct.FRST(decision.table, type.method = "sfrs", 
#                             type.QR = "fuzzy.QR", control = control)
# 
#' ########## using beta.PFRS approximation ##############
#' control <- list(t.implicator = "lukasiewicz", type.relation = c("tolerance", "eq.1"), 
#'                 beta.quasi = 0.05, type.aggregation = c("t.tnorm", "lukasiewicz"))
#' reduct.8 <- FS.quickreduct.FRST(decision.table, type.method = "beta.pfrs", 
#'                             type.QR = "fuzzy.QR", control = control)
#'
#' ########## using fuzzy discernibility matrix ##############
#' control <- list(alpha = 1, type.relation = c("tolerance", "eq.1"), 
#'                type.aggregation = c("t.tnorm", "lukasiewicz"), 
#'                 t.implicator = "lukasiewicz")
#' reduct.9 <- FS.quickreduct.FRST(decision.table, type.method = "fuzzy.discernibility", 
#'                             type.QR = "fuzzy.QR", control = control)}
#'
#' ##########################################################
#' ## Example 2: Dataset containing nominal and continuous values
#' ## In this case, we only provide one method but others work in
#' ## the same way.
#' ## In this example, we will show how to get the
#' ## new decision table as well
#' ##########################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$hiring.dt 
#' 
#' ########## using fuzzy lower approximation ##############
#' control <- list(type.aggregation = c("t.tnorm", "lukasiewicz"), 
#'                t.implicator = "lukasiewicz", type.relation = c("tolerance", "eq.1"))
#' reduct.1 <- FS.quickreduct.FRST(decision.table, type.method = "fuzzy.dependency", 
#'                             type.QR = "fuzzy.QR", control = control)
#'		
#' ## get new decision table based on reduct
#' new.decTable <- SF.applyDecTable(decision.table, reduct.1)
#'					 
#' @export
FS.quickreduct.FRST <- function(decision.table, type.method = "fuzzy.dependency", type.QR = "fuzzy.QR", control = list(), ...) {	
	
	## execute quickreduct algorithm
	super.reduct <- quickreduct.alg(decision.table, type.method, type.QR, control)
	
	## construct FeatureSubset class
	names.attrs <-  names(attr(decision.table, "desc.attrs"))	
    names(super.reduct) = names.attrs[super.reduct]
	mod <- list(reduct = super.reduct, type.method = type.method, type.task = "feature selection", model = "FRST")				
	class.mod <- ObjectFactory(mod, classname = "FeatureSubset")	
	
	return(class.mod)
}

#' This is a function implementing the near-optimal reduction algorithm by employing 
#' fuzzy variable precision rough sets (FVPRS) for feature selection
#' based on FRST proposed by (Zhao et al, 2009). 
#' 
#' The near-optimal algorithm is an algorithm to find one reduct only rather than all reducts. It modifies the \eqn{\alpha}-reduction based on
#' discernibility matrix by using a heuristic algorithm. To get basic knowledge about discernibility matrix, 
#' users can refers to the \code{"alpha.red"} discernibility type in \code{\link{BC.discernibility.mat.FRST}} . 
#' 
#' It should be noted that this function does not give the new decision table directly. 
#' The other additional function called \code{\link{SF.applyDecTable}} is used to produce the new decision table based on 
#' information about the reduct from this function.
#'
#' @title The near-optimal reduction algorithm based on fuzzy rough set theory
#' @param decision.table  a \code{"DecisionTable"} class representing the decision table. See \code{\link{SF.asDecisionTable}}.
#'                        In this case, the decision attribute must be nominal.
#' @param alpha.precision a numeric value representing variable precision of FVPRS. 
#'
#'        See \code{\link{BC.LU.approximation.FRST}}.
#' @param ... other parameters.
#' @seealso \code{\link{BC.discernibility.mat.FRST}}
#' @return A class \code{"FeatureSubset"} that contains the following components:
#' \itemize{
#' \item \code{reduct}: a list representing a single reduct. In this case, it could be a superreduct or just a subset of features.
#' \item \code{type.method}: a string representing the type of method which is \code{"near.optimal.fvprs"}.
#' \item \code{type.task}: a string showing the type of task which is \code{"feature selection"}.
#' \item \code{model}: a string representing the type of model. In this case, it is \code{"FRST"} which means fuzzy rough set theory.
#' }  
#' @references
#' S. Zhao, E. C. C. Tsang, and D. Chen, "The Model of Fuzzy Variable Precision Rough Sets",
#' IEEE Trans. on Fuzzy Systems, vol. 17, no. 2, p. 451 - 467 (2009).
#'
#' @examples
#' #########################################################
#' ## Example 1: Hiring dataset containing 8 objects with 5 attributes
#' #########################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$hiring.dt 
#' 
#' ## get reduct as FeatureSubset class
#' reduct.1 <- FS.nearOpt.fvprs.FRST(decision.table)
#'
#' ## get new decision table according to the reduct
#' new.decTable <- SF.applyDecTable(decision.table, reduct.1)
#'
#' #########################################################
#' ## Example 2: Pima dataset containing 7 objects with 9 attributes
#' #########################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$pima7.dt 
#' 
#' ## get reduct
#' reduct.2 <- FS.nearOpt.fvprs.FRST(decision.table)
#'
#' ## get new decision table according to the reduct
#' new.decTable <- SF.applyDecTable(decision.table, reduct.2)
#' @export
FS.nearOpt.fvprs.FRST <- function(decision.table, alpha.precision = 0.05, ...) {

	if (is.null(attr(decision.table, "decision.attr"))){
		stop("A decision attribute is not indicated.")
	}
	
	if (attr(decision.table, "nominal.attrs")[attr(decision.table, "decision.attr")] == FALSE){
		stop("The decision attribute must be nominal values")
	}
	
	## get the data
	objects <- decision.table
	nominal.att <- attr(decision.table, "nominal.attrs")
	desc.attrs <- attr(decision.table, "desc.attrs")
	num.att <- ncol(objects)
	num.object <- nrow(objects)
	names.attr <- t(colnames(objects))
	type.discernibility = "alpha.red"
	num.red = "near.opt"
	type.relation = c("tolerance", "eq.1")	
	t.implicator = "lukasiewicz"
	type.LU = "implicator.tnorm"
	type.aggregation <- c("t.tnorm", "lukasiewicz")
	
	## build decision-relative discernibility matrix
	res.temp <- build.discMatrix.FRST(decision.table, type.discernibility, num.red, alpha.precision, type.relation, 
		                               t.implicator, type.LU, type.aggregation = type.aggregation)

	disc.mat = res.temp$disc.mat
	disc.list = res.temp$disc.list
	
	## perform near-optimal reduction using FVPRS
	## delete redundant of discernibility matrix
	disc.list <- unique(disc.list)

	## delete blank characters
	disc.list.temp <- c()
	j <- 1
	for (i in 1 : length(disc.list)){
		if (!(is.character(disc.list[[i]]) & length(disc.list[[i]]) == 0) && !is.na(disc.list[[i]])){
			disc.list.temp[j] <- list(disc.list[[i]])
			j <- j + 1
		}
	}
	disc.list <- disc.list.temp
	
	if (length(disc.list) > 1){
		## get core
		core.red <- disc.list[which(lapply(disc.list, length) == 1)]

		if (length(core.red) != 0){
			## delete element == core (for each core) 
			disc.list <- disc.list[which(lapply(disc.list, length) > 1)]
			
			## delete element containing core
			for (i in 1 : length(core.red)){
				disc.list <- disc.list[which(lapply(disc.list, function(x){core.red[i] %in% x}) == FALSE)] 	
			}
		}		else {
			core.red <- c()
		}
		ii <- 1
		while (ii <= length(disc.list)){
		
			## get the max of freq.
			new.red <- names(which.max(table(unlist(disc.list))))
		
			## add new.red into reducts
			core.red <- c(core.red, new.red)
	
			## delete element containing new.red
			disc.list <- disc.list[which(lapply(disc.list, function(x){new.red %in% x}) == FALSE)] 

			ii <- ii + 1
		}
		## delete redundant elements
		reduct <- unlist(unique(core.red))
        reduct <- which(as.character(names.attr) %in% reduct)
		
		## construct FeatureSubset class
		mod <- list(reduct = reduct, type.method = "near.optimal.fvprs", type.task = "feature selection", model = "FRST")					
		class.mod <- ObjectFactory(mod, classname = "FeatureSubset")	
		
		return(class.mod)
		
	}	else if (length(disc.list) == 1){
		
		reduct <- unlist(sort(core.red))
		reduct = which(as.character(names.attr) %in% reduct)
        colnames(reduct) = names.attr[reduct]
		
		## construct FeatureSubset class
		mod <- list(reduct = reduct, type.method = "near.optimal.fvprs", type.task = "feature selection", model = "FRST")					
		class.mod <- ObjectFactory(mod, classname = "FeatureSubset")	
		
		return(class.mod)
	}
}

#' It is a wrapper function used for generating all reducts. The reducts are obtained from functions based on a discernibility matrix based on RST and FRST. Therefore, it should be noted that
#' before calling the function, we need to execute \code{BC.discernibility.mat.RST} and \code{BC.discernibility.mat.FRST}.
#' 
#' @title The function for computing all reducts
#'
#' @param discernibilityMatrix a \code{"DiscernibilityMatrix"} class representing the discernibility matrix of RST and FRST.
#'
#' See \code{\link{BC.discernibility.mat.RST}} and \code{\link{BC.discernibility.mat.FRST}}. 
#' @return A class \code{"ReductSet"}. 
#' @examples
#' ########################################################
#' ## Example 1: Generate all reducts and 
#' ##            a new decision table using RST
#' ########################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$hiring.dt 
#' 
#' ## build the decision-relation discernibility matrix
#' res.2 <- BC.discernibility.mat.RST(decision.table, range.object = NULL)
#' 
#' ## generate all reducts
#' reduct <- FS.all.reducts.computation(res.2)
#'
#' ## generate new decision table
#' new.decTable <- SF.applyDecTable(decision.table, reduct, control = list(indx.reduct = 1))
#'
#' ##############################################################
#' ## Example 2: Generate all reducts and 
#' ##            a new decision table using FRST
#' ##############################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$hiring.dt 
#' 
#' ## build the decision-relation discernibility matrix
#' control.1 <- list(type.relation = c("crisp"), 
#'                 type.aggregation = c("crisp"), 
#'                 t.implicator = "lukasiewicz", type.LU = "implicator.tnorm")
#' res.1 <- BC.discernibility.mat.FRST(decision.table, type.discernibility = "standard.red", 
#'                                     control = control.1)
#' 
#' ## generate single reduct
#' reduct <- FS.all.reducts.computation(res.1)
#'
#' ## generate new decision table
#' new.decTable <- SF.applyDecTable(decision.table, reduct, control = list(indx.reduct = 1))
#' @export
FS.all.reducts.computation <- function(discernibilityMatrix) {
  
  if(!inherits(discernibilityMatrix, "DiscernibilityMatrix")) {
    stop("The argument is not in the class of \'DiscernibilityMatrix\' objects.")
  }
  
  reductSet = convertCNFtoDNF(discernibilityMatrix$disc.list)
  
  core = computeCore(reductSet)
  
  reductSet <- list(decision.reduct = reductSet, 
                    core = core, 
                    discernibility.type = discernibilityMatrix$type.discernibility, 
                    type.task = "computation of all reducts", 
                    type.model = discernibilityMatrix$type.model)  				
  reductSet <- ObjectFactory(reductSet, classname = "ReductSet")
  
  return(reductSet)
}

#' It is a function for computing one reduct from a discernibility matrix - it can be the greedy heuristic or a randomized search. 
#' 
#' @title The function for computing one reducts
#'
#' @param discernibilityMatrix a \code{"DiscernibilityMatrix"} class representing the discernibility matrix of RST and FRST.
#' @param greedy a boolean value whether we are using the greedy heuristic or a randomized search.
#' @param power a numeric representing a parameter of the greedy heuristic.
#'
#' See \code{\link{BC.discernibility.mat.RST}} and \code{\link{BC.discernibility.mat.FRST}}. 
#' @return A class \code{"ReductSet"}. 
#' @examples
#' ########################################################
#' ## Example 1: Generate one reducts and 
#' ##            a new decision table using RST
#' ########################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$hiring.dt 
#' 
#' ## build the decision-relation discernibility matrix
#' res.1 <- BC.discernibility.mat.RST(decision.table, range.object = NULL)
#' 
#' ## generate all reducts
#' reduct <- FS.one.reduct.computation(res.1)
#'
#' ## generate new decision table
#' new.decTable <- SF.applyDecTable(decision.table, reduct, control = list(indx.reduct = 1))
#'
#' ##############################################################
#' ## Example 2: Generate one reducts and 
#' ##            a new decision table using FRST
#' ##############################################################
#' data(RoughSetData)
#' decision.table <- RoughSetData$hiring.dt 
#' 
#' ## build the decision-relation discernibility matrix
#' control <- list(type.relation = c("crisp"), 
#'                 type.aggregation = c("crisp"), 
#'                 t.implicator = "lukasiewicz", type.LU = "implicator.tnorm")
#' res.2 <- BC.discernibility.mat.FRST(decision.table, type.discernibility = "standard.red", 
#'                                     control = control)
#' 
#' ## generate single reduct
#' reduct <- FS.one.reduct.computation(res.2)
#'
#' ## generate new decision table
#' new.decTable <- SF.applyDecTable(decision.table, reduct, control = list(indx.reduct = 1))
#' @export
FS.one.reduct.computation <- function(discernibilityMatrix, greedy = TRUE, power = 2) {
  
  if(!inherits(discernibilityMatrix, "DiscernibilityMatrix")) {
    stop("The argument is not in the class of \'DiscernibilityMatrix\' objects.")
  }
  
  CNFclauses = discernibilityMatrix$disc.list
  
  reduct = character()
  tmpIdx = rep(TRUE, length(CNFclauses))
  attrInvertedIdx = list()
  
  while(any(tmpIdx)) {
    attributeCounts = table(unlist(CNFclauses[tmpIdx], use.names = FALSE))
    
    if(greedy) bestAttr = which.max(attributeCounts)
    else bestAttr = sample(length(attributeCounts), 1, prob = attributeCounts^power)
    
    tmpName = names(attributeCounts)[bestAttr]
    reduct = append(reduct, tmpName)
    attrInvertedIdx = append(attrInvertedIdx, list(sapply(CNFclauses, function(clause) tmpName %in% clause)))
    tmpIdx = tmpIdx & !attrInvertedIdx[[length(attrInvertedIdx)]]
  }
  rm(tmpIdx, tmpName, attributeCounts, bestAttr)
  
  if(length(reduct) > 1) {
    attrInvertedIdx = do.call(cbind, attrInvertedIdx)
    tmpSums = rowSums(attrInvertedIdx)
    for(i in (ncol(attrInvertedIdx) - 1):1) {
      if(all(tmpSums > 1) || !(any(attrInvertedIdx[tmpSums == 1,i]))) {
        reduct = reduct[-i]
        attrInvertedIdx = attrInvertedIdx[ , -i, drop = FALSE]
        tmpSums = rowSums(attrInvertedIdx)
      }
    }
  }
  
  reduct <- list(decision.reduct = list(reduct), 
                 core = NULL, 
                 discernibility.type = discernibilityMatrix$type.discernibility, 
                 type.task = "computation of one reduct from a discernibility matrix", 
                 type.model = discernibilityMatrix$type.model)    			
  reduct <- ObjectFactory(reduct, classname = "ReductSet")
  return(reduct)
}



